{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "from SmilesPE.tokenizer import *\n",
    "from SmilesPE.spe2vec import *\n",
    "from SmilesPE.learner import corpus_augment\n",
    "import codecs\n",
    "from SmilesPE.tokenizer import *\n",
    "from SmilesPE.spe2vec import *\n",
    "from SmilesPE.learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./data/clean_chembl25/clean_chembl25.smi\"\n",
    "\n",
    "with open(file_name, \"r\") as ins:\n",
    "    SMILES = []\n",
    "    for line in ins:\n",
    "        SMILES.append(line.split('\\n')[0])\n",
    "print('Number of SMILES:', len(SMILES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edcc064",
   "metadata": {},
   "source": [
    "### Saving Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output = codecs.open('./SPE_ChEMBL.txt', 'w')\n",
    "learn_SPE(SMILES, output, 30000, min_frequency=2000, augmentation=1, verbose=True, total_symbols=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692c346",
   "metadata": {},
   "source": [
    "### Prerparing large corpus by augmenting SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = './clean_chembl25/clean_chembl25.smi'\n",
    "outdir = './data/aug_chembl/'\n",
    "\n",
    "corpus_augment(infile, outdir, cycles = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd06038",
   "metadata": {},
   "source": [
    "### Train with skip-gram algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from SmilesPE.tokenizer import *\n",
    "from SmilesPE.spe2vec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spe_vob= codecs.open('./SPE_ChEMBL.txt')\n",
    "spe = SPE_Tokenizer(spe_vob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ca6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = './data/aug_chembl/'\n",
    "corpus = Corpus(indir, tokenizer=spe, isdir=True, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b3067",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = learn_spe2vec(corpus=corpus, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('.data/results/spe_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c8248",
   "metadata": {},
   "source": [
    "### Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c45f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_spe2vec('./data/results/spe_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbd7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f69294",
   "metadata": {},
   "source": [
    "### The embedding of one token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f657599",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv['Cl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e3fef",
   "metadata": {},
   "source": [
    "### Tokenize the SMILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6199e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from SmilesPE.tokenizer import *\n",
    "spe_vob= codecs.open('./SPE_ChEMBL.txt')\n",
    "spe = SPE_Tokenizer(spe_vob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "spe2vec = SPE2Vec('./data/results/spe_model.bin', spe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "smi = 'CC(=O)NCCC1=CNc2c1cc(OC)cc2CC(=O)NCCc1c[nH]c2ccc(OC)cc12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = spe2vec.tokenize(smi)\n",
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef4858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
